{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"roberta_sentiment.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1QOBUsJHTV0gbfn_97Bj5zlaU0JJVp3Wy","authorship_tag":"ABX9TyOv8I+SxTGb1wY54POwJfxL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3ace3e80e147436b9af2bf00996067a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b5e0e96f341442e49dce9d01b0dc1cea","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1ef0665302af49069e3d6ba112d4ffcc","IPY_MODEL_f9ab58b14e1b475fbdc7c3bb584b9785"]}},"b5e0e96f341442e49dce9d01b0dc1cea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1ef0665302af49069e3d6ba112d4ffcc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7b4fd84fd12d4e539c0d118d6da60d2e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d51d57232d204b07a5e99048fb4ee256"}},"f9ab58b14e1b475fbdc7c3bb584b9785":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8093a56348d64a019005e3c691420e46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 937kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a8c140c4d58a4a11a159beacd6f3db48"}},"7b4fd84fd12d4e539c0d118d6da60d2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d51d57232d204b07a5e99048fb4ee256":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8093a56348d64a019005e3c691420e46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a8c140c4d58a4a11a159beacd6f3db48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b268747b4d9246e99195c0b684a30307":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ed535913de54a11a0fc866a49625e07","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_25d83084f0754fa08cf94763fe28aa2e","IPY_MODEL_5957e4f3b1b74419b532345e494927f8"]}},"8ed535913de54a11a0fc866a49625e07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"25d83084f0754fa08cf94763fe28aa2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c8f3d6b05ebf475aa3094b8aaa9ea9fe","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_62fce439ba5545a19b38e6883bc66cbc"}},"5957e4f3b1b74419b532345e494927f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0b16e143d7864a9dbfdf8a3695db3e50","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 255kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de303de061b34d808dbc0059380d0492"}},"c8f3d6b05ebf475aa3094b8aaa9ea9fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"62fce439ba5545a19b38e6883bc66cbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b16e143d7864a9dbfdf8a3695db3e50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"de303de061b34d808dbc0059380d0492":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7a381af92d04dc49aaa655e4b3a6024":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_81e802eaaf4d472392dfc9e22839bd7f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3d3f20d9a9b84281b729a3c3380995a8","IPY_MODEL_e6d8416f2c124850948dcd7c9a3a5145"]}},"81e802eaaf4d472392dfc9e22839bd7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d3f20d9a9b84281b729a3c3380995a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1c813b3e72b04beaa7bcc2922d657812","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34bb9b3a59664bad9c3f08d2d94f26eb"}},"e6d8416f2c124850948dcd7c9a3a5145":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f50a3e5743d6402ca7d141c9c954bf27","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:00&lt;00:00, 3.11MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae0d84f5939c4aaaa06fc12fe120d43b"}},"1c813b3e72b04beaa7bcc2922d657812":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"34bb9b3a59664bad9c3f08d2d94f26eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f50a3e5743d6402ca7d141c9c954bf27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ae0d84f5939c4aaaa06fc12fe120d43b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDTaJPIMaZq9","executionInfo":{"status":"ok","timestamp":1617005650031,"user_tz":-480,"elapsed":7268,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"cfbb5461-23ce-41bc-9e61-e4d01c9192ee"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/d5/f4157a376b8a79489a76ce6cfe147f4f3be1e029b7144fa7b8432e8acb26/transformers-4.4.2-py3-none-any.whl (2.0MB)\n","\r\u001b[K     |▏                               | 10kB 23.5MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 16.8MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 14.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 13.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 8.5MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 9.1MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 9.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 81kB 10.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 9.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 102kB 8.3MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112kB 8.3MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 133kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 143kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 153kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 163kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 174kB 8.3MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 194kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 204kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 215kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 225kB 8.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 235kB 8.3MB/s eta 0:00:01\r\u001b[K     |████                            | 245kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 256kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 266kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 276kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 286kB 8.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 296kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 307kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 317kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 327kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 337kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 348kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 358kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 368kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 378kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 389kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 399kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 409kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 419kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 430kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 440kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 450kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 460kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 471kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 481kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 491kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 501kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 512kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 522kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 532kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 542kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 552kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 563kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 573kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 583kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 593kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 604kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 614kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 624kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 634kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 645kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 655kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 665kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 675kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 686kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 696kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 706kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 716kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 727kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 737kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 747kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 757kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 768kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 778kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 788kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 798kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 808kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 819kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 829kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 839kB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 849kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 860kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 870kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 880kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 890kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 901kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 911kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 921kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 931kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 942kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 952kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 962kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 972kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 983kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 993kB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.1MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.3MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.6MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.9MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.0MB 8.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.0MB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 51.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 60.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=346c35d8181c89f3bd7a2f401fb8eab7efa24eef838a33154a7e051b699e2184\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1kNPWk6Uag9Y","executionInfo":{"status":"ok","timestamp":1617005652102,"user_tz":-480,"elapsed":904,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["data_path = 'drive/MyDrive/datasets/roberta_senti.tsv'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"r5YmatIpaufv","executionInfo":{"status":"ok","timestamp":1617005658055,"user_tz":-480,"elapsed":5339,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import transformers\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from torch import cuda\n","from transformers import RobertaTokenizer, RobertaModel\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns\n","import json\n","import logging\n","logging.basicConfig(level=logging.ERROR)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Ef96pnjPnW9n","executionInfo":{"status":"ok","timestamp":1617005659733,"user_tz":-480,"elapsed":773,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"04f325e1-25fb-4d50-f654-496807da3e08"},"source":["device = 'cuda' if cuda.is_available() else 'cpu'\n","device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cuda'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"NdUD5WlenqDv","executionInfo":{"status":"ok","timestamp":1617005662893,"user_tz":-480,"elapsed":2418,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"871db46c-b03b-40c1-eb29-043d55b69443"},"source":["dataset = pd.read_csv(data_path, delimiter='\\t')\n","dataset.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PhraseId</th>\n","      <th>SentenceId</th>\n","      <th>Phrase</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>A series</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>series</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   PhraseId  ...  Sentiment\n","0         1  ...          1\n","1         2  ...          2\n","2         3  ...          2\n","3         4  ...          2\n","4         5  ...          2\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yz5FvwZ5n_Wi","executionInfo":{"status":"ok","timestamp":1617005664021,"user_tz":-480,"elapsed":487,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"734c1a08-6222-4ec2-9fab-0a12dc4edf1f"},"source":["dataset.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(156060, 4)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGX_AKTnoG43","executionInfo":{"status":"ok","timestamp":1617005665410,"user_tz":-480,"elapsed":635,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"1323c78f-6e9b-40bd-dfe7-b85ec85c7b7c"},"source":["dataset.Sentiment.unique()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 2, 3, 4, 0])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"0HYkcN50oNz-","executionInfo":{"status":"ok","timestamp":1617005666464,"user_tz":-480,"elapsed":528,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"ce8492ca-0a6c-4f3a-cb87-de8d1dd25f10"},"source":["dataset.describe()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PhraseId</th>\n","      <th>SentenceId</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>156060.000000</td>\n","      <td>156060.000000</td>\n","      <td>156060.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>78030.500000</td>\n","      <td>4079.732744</td>\n","      <td>2.063578</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>45050.785842</td>\n","      <td>2502.764394</td>\n","      <td>0.893832</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>39015.750000</td>\n","      <td>1861.750000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>78030.500000</td>\n","      <td>4017.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>117045.250000</td>\n","      <td>6244.000000</td>\n","      <td>3.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>156060.000000</td>\n","      <td>8544.000000</td>\n","      <td>4.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            PhraseId     SentenceId      Sentiment\n","count  156060.000000  156060.000000  156060.000000\n","mean    78030.500000    4079.732744       2.063578\n","std     45050.785842    2502.764394       0.893832\n","min         1.000000       1.000000       0.000000\n","25%     39015.750000    1861.750000       2.000000\n","50%     78030.500000    4017.000000       2.000000\n","75%    117045.250000    6244.000000       3.000000\n","max    156060.000000    8544.000000       4.000000"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"wuTn349boSH7","executionInfo":{"status":"ok","timestamp":1617005668153,"user_tz":-480,"elapsed":776,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"23ea632e-0c31-4c5e-9fe6-3042e5b2b58e"},"source":["new_df = dataset[['Phrase','Sentiment']]\n","new_df.head()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Phrase</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A series</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>series</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Phrase  Sentiment\n","0  A series of escapades demonstrating the adage ...          1\n","1  A series of escapades demonstrating the adage ...          2\n","2                                           A series          2\n","3                                                  A          2\n","4                                             series          2"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuy204eJ5tM7","executionInfo":{"status":"ok","timestamp":1617005669942,"user_tz":-480,"elapsed":1109,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"6d3576a8-de64-4ac0-f510-ae864ea3a93a"},"source":["def prepare(x):\n","    return ' '.join(str(x).split())\n","new_df.Phrase.apply(prepare)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0         A series of escapades demonstrating the adage ...\n","1         A series of escapades demonstrating the adage ...\n","2                                                  A series\n","3                                                         A\n","4                                                    series\n","                                ...                        \n","156055                                            Hearst 's\n","156056                            forced avuncular chortles\n","156057                                   avuncular chortles\n","156058                                            avuncular\n","156059                                             chortles\n","Name: Phrase, Length: 156060, dtype: object"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"QQVjZa386CvA","executionInfo":{"status":"ok","timestamp":1617005671086,"user_tz":-480,"elapsed":560,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"217f055e-1b52-43f1-d42b-aac8cab2bd68"},"source":["new_df.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Phrase</th>\n","      <th>Sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A series of escapades demonstrating the adage ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A series</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>series</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              Phrase  Sentiment\n","0  A series of escapades demonstrating the adage ...          1\n","1  A series of escapades demonstrating the adage ...          2\n","2                                           A series          2\n","3                                                  A          2\n","4                                             series          2"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["3ace3e80e147436b9af2bf00996067a9","b5e0e96f341442e49dce9d01b0dc1cea","1ef0665302af49069e3d6ba112d4ffcc","f9ab58b14e1b475fbdc7c3bb584b9785","7b4fd84fd12d4e539c0d118d6da60d2e","d51d57232d204b07a5e99048fb4ee256","8093a56348d64a019005e3c691420e46","a8c140c4d58a4a11a159beacd6f3db48","b268747b4d9246e99195c0b684a30307","8ed535913de54a11a0fc866a49625e07","25d83084f0754fa08cf94763fe28aa2e","5957e4f3b1b74419b532345e494927f8","c8f3d6b05ebf475aa3094b8aaa9ea9fe","62fce439ba5545a19b38e6883bc66cbc","0b16e143d7864a9dbfdf8a3695db3e50","de303de061b34d808dbc0059380d0492","d7a381af92d04dc49aaa655e4b3a6024","81e802eaaf4d472392dfc9e22839bd7f","3d3f20d9a9b84281b729a3c3380995a8","e6d8416f2c124850948dcd7c9a3a5145","1c813b3e72b04beaa7bcc2922d657812","34bb9b3a59664bad9c3f08d2d94f26eb","f50a3e5743d6402ca7d141c9c954bf27","ae0d84f5939c4aaaa06fc12fe120d43b"]},"id":"oVj1ImBcpO5c","executionInfo":{"status":"ok","timestamp":1617005675726,"user_tz":-480,"elapsed":3873,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"61e7c571-a1eb-4dfc-c174-841732b8c7d5"},"source":["MAX_LEN = 256\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 4\n","# EPOCHS = 1\n","LEARNING_RATE = 1e-05\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ace3e80e147436b9af2bf00996067a9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b268747b4d9246e99195c0b684a30307","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7a381af92d04dc49aaa655e4b3a6024","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TdKfMNIvpXGv","executionInfo":{"status":"ok","timestamp":1617006338558,"user_tz":-480,"elapsed":852,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["import torch.nn.functional as F\n","class SentiData(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe.Phrase\n","        self.targets = self.data.Sentiment\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer(\n","            text,\n","            padding='max_length',\n","            max_length=512,\n","            return_token_type_ids=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': F.one_hot(torch.tensor(self.targets[index]), num_classes=5)\n","        }"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"QQsPWux_uImb","executionInfo":{"status":"ok","timestamp":1617006343946,"user_tz":-480,"elapsed":734,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["train_size = 0.8\n","train_data = new_df.sample(frac=train_size, random_state=200)\n","test_data = new_df.drop(train_data.index).reset_index(drop=True)\n","train_data = train_data.reset_index(drop=True)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"BKynJOEq1nUA","executionInfo":{"status":"ok","timestamp":1617005705557,"user_tz":-480,"elapsed":21556,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["train_encoddings = tokenizer(train_data.Phrase.to_list(), padding=True, truncation=True, max_length=512, return_token_type_ids=True)\n","test_encoddings = tokenizer(test_data.Phrase.to_list(), padding=True, truncation=True, max_length=512, return_token_type_ids=True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y9Ipq49d2T57","executionInfo":{"status":"ok","timestamp":1617005708385,"user_tz":-480,"elapsed":755,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["class SentimentData(torch.utils.data.Dataset):\n","    def __init__(self, encodding, targets):\n","        self.encodding = encodding\n","        self.targets = targets\n","    \n","    def __len__(self):\n","        return len(self.targets)\n","\n","    def __getitem__(self, index):\n","        item = {k: torch.tensor(self.targets[index]) for k,v in self.encodding.items()}\n","        item['targets'] = torch.tensor(self.targets[index])\n","        return item"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNzM3ldP4TGo","executionInfo":{"status":"ok","timestamp":1617006348674,"user_tz":-480,"elapsed":776,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["# train_set = SentimentData(train_encoddings, train_data.Sentiment.to_list())\n","# test_set = SentimentData(test_encoddings, test_data.Sentiment.to_list())\n","train_set = SentiData(train_data, tokenizer, MAX_LEN)\n","test_set = SentiData(test_data, tokenizer, MAX_LEN)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGlxV2rG1zK6","executionInfo":{"status":"ok","timestamp":1617006351628,"user_tz":-480,"elapsed":731,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE, 'shuffle': True, 'num_workers': 0}\n","valid_params = train_params = {'batch_size': VALID_BATCH_SIZE, 'shuffle': True, 'num_workers': 0}"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"12yCgEsu2aQ7","executionInfo":{"status":"ok","timestamp":1617006352816,"user_tz":-480,"elapsed":483,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["train_loader = DataLoader(train_set, **train_params)\n","test_loader = DataLoader(test_set, **valid_params)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDg07teP2oGY","executionInfo":{"status":"ok","timestamp":1617006356549,"user_tz":-480,"elapsed":666,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["class RobertaSenti(torch.nn.Module):\n","    def __init__(self):\n","        super(RobertaSenti, self).__init__()\n","        self.l1 = RobertaModel.from_pretrained('roberta-base')\n","        self.pre_classfiler = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classfiler = torch.nn.Linear(768, 5)\n","\n","    def forward(self, input_ids, mask, token_type_ids):\n","        o1 = self.l1(input_ids=input_ids, attention_mask=mask, token_type_ids=token_type_ids)\n","        hidden_state = o1[0]\n","        pooler = self.pre_classfiler(hidden_state)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classfiler(pooler)\n","        return output"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAnIttfm4p6X","executionInfo":{"status":"ok","timestamp":1617006362400,"user_tz":-480,"elapsed":3796,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"5f42f47b-bfb1-463b-d127-e106279f57a6"},"source":["model = RobertaSenti()\n","model.to(device)"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RobertaSenti(\n","  (l1): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classfiler): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classfiler): Linear(in_features=768, out_features=5, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"0ac0vBQF4vfm","executionInfo":{"status":"ok","timestamp":1617006382047,"user_tz":-480,"elapsed":796,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["def calcuc_acc(preds, targets):\n","    return (preds==targets).sum().item()"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"NicgaL2L5POl","executionInfo":{"status":"ok","timestamp":1617006383526,"user_tz":-480,"elapsed":845,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["loss_func = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdL1Rzl85haQ","executionInfo":{"status":"ok","timestamp":1617006384993,"user_tz":-480,"elapsed":807,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}}},"source":["def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _, data in tqdm(enumerate(train_loader, 0)):\n","        ids = data['ids'].to(device)\n","        mask = data['mask'].to(device)\n","        token_type_ids = data['token_type_ids'].to(device)\n","        targets = data['targets'].to(device)\n","\n","        outputs = model(ids, mask, token_type_ids)\n","        loss = loss_func(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calcuc_acc(big_idx, targets)\n","        nb_tr_steps += 1\n","        nb_tr_examples += targets.size(0)\n","\n","        if _%5000==0:\n","            loss_step = tr_loss/nb_tr_steps\n","            accu_step = (n_correct*100)/nb_tr_examples \n","            print(f\"Training Loss per 5000 steps: {loss_step}\")\n","            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_accu = (n_correct*100)/nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-ousTlg7A42","executionInfo":{"status":"ok","timestamp":1617014040502,"user_tz":-480,"elapsed":3453813,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"cdf3e0a6-9107-4e8d-ffb9-88e70bf5b9d4"},"source":["for i in range(1):\n","    train(i)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["1it [00:00,  3.38it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 6.241222858428955\n","Training Accuracy per 5000 steps: 0.0\n"],"name":"stdout"},{"output_type":"stream","text":["5001it [20:25,  4.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 0.4464766506386492\n","Training Accuracy per 5000 steps: 415.6018796240752\n"],"name":"stdout"},{"output_type":"stream","text":["10001it [40:49,  4.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 0.37389095457647514\n","Training Accuracy per 5000 steps: 422.7002299770023\n"],"name":"stdout"},{"output_type":"stream","text":["15001it [1:01:16,  4.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 0.3459600212539079\n","Training Accuracy per 5000 steps: 426.28158122791814\n"],"name":"stdout"},{"output_type":"stream","text":["20001it [1:21:42,  4.07it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 0.3299183544467355\n","Training Accuracy per 5000 steps: 428.32733363331835\n"],"name":"stdout"},{"output_type":"stream","text":["25001it [1:42:09,  4.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 0.32028371942940737\n","Training Accuracy per 5000 steps: 429.5498180072797\n"],"name":"stdout"},{"output_type":"stream","text":["30001it [2:02:35,  4.06it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training Loss per 5000 steps: 0.3129374257041677\n","Training Accuracy per 5000 steps: 430.59564681177295\n"],"name":"stdout"},{"output_type":"stream","text":["31212it [2:07:32,  4.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["The Total Accuracy for Epoch 0: 430.8342945021146\n","Training Loss Epoch: 0.311398440821763\n","Training Accuracy Epoch: 430.8342945021146\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhY2uZIT4Lki","executionInfo":{"status":"ok","timestamp":1617006374157,"user_tz":-480,"elapsed":828,"user":{"displayName":"dan lu","photoUrl":"","userId":"10648781224105514833"}},"outputId":"4968d5f7-7d5d-4f60-b14f-a7d4ca7b4e32"},"source":["for _, data in enumerate(train_loader, 0):\n","    print(data['targets'])\n","    break"],"execution_count":40,"outputs":[{"output_type":"stream","text":["tensor([[0, 1, 0, 0, 0],\n","        [0, 0, 1, 0, 0],\n","        [0, 0, 1, 0, 0],\n","        [0, 0, 1, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4s61pD_c51JZ"},"source":[""],"execution_count":null,"outputs":[]}]}