{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = load_files(r'D:\\pySource\\anaconda\\ML\\data\\mlcomp\\379\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(13180, 20)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(new_train.data), len(new_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(encoding='latin-1')\n",
    "X_train = vectorizer.fit_transform((d for d in new_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('D:\\\\pySource\\\\anaconda\\\\ML\\\\data\\\\mlcomp\\\\379\\\\train\\\\talk.politics.misc\\\\17860-178992',\n 108)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "new_train.filenames[0], X_train[0].getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(13180, 130274)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9978755690440061"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "y_train = new_train.target\n",
    "clf = MultinomialNB(alpha=0.0001)\n",
    "clf.fit(X_train, y_train)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = load_files(r'D:\\pySource\\anaconda\\ML\\data\\mlcomp\\379\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform((d for d in new_test.data))\n",
    "y_test = new_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5648, 130274)"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('D:\\\\pySource\\\\anaconda\\\\ML\\\\data\\\\mlcomp\\\\379\\\\test\\\\rec.autos\\\\7429-103268',\n 'rec.autos')"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "pred = clf.predict(X_test[0])\n",
    "new_test.filenames[0], new_test.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'rec.autos'"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "new_test.target_names[new_test.target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MultinomialNB(alpha=0.0001, class_prior=None, fit_prior=True)\n                          precision    recall  f1-score   support\n\n             alt.atheism       0.90      0.91      0.91       245\n           comp.graphics       0.80      0.90      0.85       298\n comp.os.ms-windows.misc       0.82      0.79      0.80       292\ncomp.sys.ibm.pc.hardware       0.81      0.80      0.81       301\n   comp.sys.mac.hardware       0.90      0.91      0.91       256\n          comp.windows.x       0.88      0.88      0.88       297\n            misc.forsale       0.87      0.81      0.84       290\n               rec.autos       0.92      0.93      0.92       324\n         rec.motorcycles       0.96      0.96      0.96       294\n      rec.sport.baseball       0.97      0.94      0.96       315\n        rec.sport.hockey       0.96      0.99      0.98       302\n               sci.crypt       0.95      0.96      0.95       297\n         sci.electronics       0.91      0.85      0.88       313\n                 sci.med       0.96      0.96      0.96       277\n               sci.space       0.94      0.97      0.96       305\n  soc.religion.christian       0.93      0.96      0.94       293\n      talk.politics.guns       0.91      0.96      0.93       246\n   talk.politics.mideast       0.96      0.98      0.97       296\n      talk.politics.misc       0.90      0.90      0.90       236\n      talk.religion.misc       0.89      0.78      0.83       171\n\n               micro avg       0.91      0.91      0.91      5648\n               macro avg       0.91      0.91      0.91      5648\n            weighted avg       0.91      0.91      0.91      5648\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(clf)\n",
    "print(classification_report(y_test, pred, target_names=new_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}